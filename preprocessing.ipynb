{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_audio_frame_stack(sound_data, frame_length, hop_length_frame):\n",
    "    \"\"\"This function take an audio and split into several frame\n",
    "       in a numpy matrix of size (nb_frame,frame_length)\"\"\"\n",
    "\n",
    "    sequence_sample_length = sound_data.shape[0]\n",
    "\n",
    "    sound_data_list = [sound_data[start:start + frame_length] for start in range(\n",
    "    0, sequence_sample_length - frame_length + 1, hop_length_frame)]  # get sliding windows\n",
    "    sound_data_array = np.vstack(sound_data_list)\n",
    "\n",
    "    return sound_data_array\n",
    "\n",
    "\n",
    "def audio_files_to_numpy(audio_dir, list_audio_files, sample_rate, frame_length, hop_length_frame, min_duration):\n",
    "    \"\"\"This function take audio files of a directory and merge them\n",
    "    in a numpy matrix of size (nb_frame,frame_length) for a sliding window of size hop_length_frame\"\"\"\n",
    "\n",
    "    list_sound_array = []\n",
    "\n",
    "    for file in list_audio_files:\n",
    "        # open the audio file\n",
    "        y, sr = librosa.load(os.path.join(audio_dir, file), sr=sample_rate)\n",
    "        total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        if (total_duration >= min_duration):\n",
    "            list_sound_array.append(audio_to_audio_frame_stack(\n",
    "                y, frame_length, hop_length_frame))\n",
    "        else:\n",
    "            print(\n",
    "                f\"The following file {os.path.join(audio_dir,file)} is below the min duration\")\n",
    "\n",
    "    return np.vstack(list_sound_array)\n",
    "\n",
    "\n",
    "def blend_noise_randomly(voice, noise, nb_samples, frame_length):\n",
    "    \"\"\"This function takes as input numpy arrays representing frames\n",
    "    of voice sounds, noise sounds and the number of frames to be created\n",
    "    and return numpy arrays with voice randomly blend with noise\"\"\"\n",
    "\n",
    "    prod_voice = np.zeros((nb_samples, frame_length))\n",
    "    prod_noise = np.zeros((nb_samples, frame_length))\n",
    "    prod_noisy_voice = np.zeros((nb_samples, frame_length))\n",
    "\n",
    "    for i in range(nb_samples):\n",
    "        id_voice = np.random.randint(0, voice.shape[0])\n",
    "        id_noise = np.random.randint(0, noise.shape[0])\n",
    "        level_noise = np.random.uniform(0.2, 0.8)\n",
    "        prod_voice[i, :] = voice[id_voice, :]\n",
    "        prod_noise[i, :] = level_noise * noise[id_noise, :]\n",
    "        prod_noisy_voice[i, :] = prod_voice[i, :] + prod_noise[i, :]\n",
    "\n",
    "    return prod_voice, prod_noise, prod_noisy_voice\n",
    "\n",
    "\n",
    "def audio_to_magnitude_db_and_phase(n_fft, hop_length_fft, audio):\n",
    "    \"\"\"This function takes an audio and convert into spectrogram,\n",
    "       it returns the magnitude in dB and the phase\"\"\"\n",
    "\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(\n",
    "        stftaudio_magnitude, ref=np.max)\n",
    "\n",
    "    return stftaudio_magnitude_db, stftaudio_phase\n",
    "\n",
    "\n",
    "def numpy_audio_to_matrix_spectrogram(numpy_audio, dim_square_spec, n_fft, hop_length_fft):\n",
    "    \"\"\"This function takes as input a numpy audi of size (nb_frame,frame_length), and return\n",
    "    a numpy containing the matrix spectrogram for amplitude in dB and phase. It will have the size\n",
    "    (nb_frame,dim_square_spec,dim_square_spec)\"\"\"\n",
    "\n",
    "    nb_audio = numpy_audio.shape[0]\n",
    "\n",
    "    m_mag_db = np.zeros((nb_audio, dim_square_spec, dim_square_spec))\n",
    "    m_phase = np.zeros((nb_audio, dim_square_spec, dim_square_spec), dtype=complex)\n",
    "\n",
    "    for i in range(nb_audio):\n",
    "        m_mag_db[i, :, :], m_phase[i, :, :] = audio_to_magnitude_db_and_phase(n_fft, hop_length_fft, numpy_audio[i])\n",
    "\n",
    "    return m_mag_db, m_phase\n",
    "\n",
    "\n",
    "def magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, stftaudio_magnitude_db, stftaudio_phase):\n",
    "    \"\"\"This functions reverts a spectrogram to an audio\"\"\"\n",
    "\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    # taking magnitude and phase of audio\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "    audio_reconstruct = librosa.core.istft(audio_reverse_stft, hop_length=hop_length_fft, length=frame_length)\n",
    "\n",
    "    return audio_reconstruct\n",
    "\n",
    "def matrix_spectrogram_to_numpy_audio(m_mag_db, m_phase, frame_length, hop_length_fft)  :\n",
    "    \"\"\"This functions reverts the matrix spectrograms to numpy audio\"\"\"\n",
    "\n",
    "    list_audio = []\n",
    "    nb_spec = m_mag_db.shape[0]\n",
    "\n",
    "    for i in range(nb_spec):\n",
    "        audio_reconstruct = magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, m_mag_db[i], m_phase[i])\n",
    "        list_audio.append(audio_reconstruct)\n",
    "\n",
    "    return np.vstack(list_audio)\n",
    "\n",
    "def scaled_in(matrix_spec):\n",
    "    \"global scaling apply to noisy voice spectrograms (scale between -1 and 1)\"\n",
    "    matrix_spec = (matrix_spec + 46)/50\n",
    "    return matrix_spec\n",
    "\n",
    "def scaled_ou(matrix_spec):\n",
    "    \"global scaling apply to noise models spectrograms (scale between -1 and 1)\"\n",
    "    matrix_spec = (matrix_spec -6 )/82\n",
    "    return matrix_spec\n",
    "\n",
    "def inv_scaled_in(matrix_spec):\n",
    "    \"inverse global scaling apply to noisy voices spectrograms\"\n",
    "    matrix_spec = matrix_spec * 50 - 46\n",
    "    return matrix_spec\n",
    "\n",
    "def inv_scaled_ou(matrix_spec):\n",
    "    \"inverse global scaling apply to noise models spectrograms\"\n",
    "    matrix_spec = matrix_spec * 82 + 6\n",
    "    return matrix_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(noise_dir, voice_dir, path_save_time_serie, path_save_sound, path_save_spectrogram, sample_rate,\n",
    "min_duration, frame_length, hop_length_frame, hop_length_frame_noise, nb_samples, n_fft, hop_length_fft):\n",
    "    \"\"\"This function will randomly blend some clean voices from voice_dir with some noises from noise_dir\n",
    "    and save the spectrograms of noisy voice, noise and clean voices to disk as well as complex phase,\n",
    "    time series and sounds. This aims at preparing datasets for denoising training. It takes as inputs\n",
    "    parameters defined in args module\"\"\"\n",
    "\n",
    "    list_noise_files = os.listdir(noise_dir)\n",
    "    list_voice_files = os.listdir(voice_dir)\n",
    "\n",
    "    def remove_ds_store(lst):\n",
    "        \"\"\"remove mac specific file if present\"\"\"\n",
    "        if '.DS_Store' in lst:\n",
    "            lst.remove('.DS_Store')\n",
    "\n",
    "        return lst\n",
    "\n",
    "    list_noise_files = remove_ds_store(list_noise_files)\n",
    "    list_voice_files = remove_ds_store(list_voice_files)\n",
    "\n",
    "    nb_voice_files = len(list_voice_files)\n",
    "    nb_noise_files = len(list_noise_files)\n",
    "\n",
    "\n",
    "    # Extracting noise and voice from folder and convert to numpy\n",
    "    noise = audio_files_to_numpy(noise_dir, list_noise_files, sample_rate,\n",
    "                                     frame_length, hop_length_frame_noise, min_duration)\n",
    "\n",
    "    voice = audio_files_to_numpy(voice_dir, list_voice_files,\n",
    "                                     sample_rate, frame_length, hop_length_frame, min_duration)\n",
    "\n",
    "    # Blend some clean voices with random selected noises (and a random level of noise)\n",
    "    prod_voice, prod_noise, prod_noisy_voice = blend_noise_randomly(\n",
    "            voice, noise, nb_samples, frame_length)\n",
    "\n",
    "    # To save the long audio generated to disk to QC:\n",
    "    noisy_voice_long = prod_noisy_voice.reshape(1, nb_samples * frame_length)\n",
    "    librosa.output.write_wav(path_save_sound + 'noisy_voice_long.wav', noisy_voice_long[0, :], sample_rate)\n",
    "    voice_long = prod_voice.reshape(1, nb_samples * frame_length)\n",
    "    librosa.output.write_wav(path_save_sound + 'voice_long.wav', voice_long[0, :], sample_rate)\n",
    "    noise_long = prod_noise.reshape(1, nb_samples * frame_length)\n",
    "    librosa.output.write_wav(path_save_sound + 'noise_long.wav', noise_long[0, :], sample_rate)\n",
    "\n",
    "    # Squared spectrogram dimensions\n",
    "    dim_square_spec = int(n_fft / 2) + 1\n",
    "\n",
    "    # Create Amplitude and phase of the sounds\n",
    "    m_amp_db_voice,  m_pha_voice = numpy_audio_to_matrix_spectrogram(\n",
    "            prod_voice, dim_square_spec, n_fft, hop_length_fft)\n",
    "    m_amp_db_noise,  m_pha_noise = numpy_audio_to_matrix_spectrogram(\n",
    "            prod_noise, dim_square_spec, n_fft, hop_length_fft)\n",
    "    m_amp_db_noisy_voice,  m_pha_noisy_voice = numpy_audio_to_matrix_spectrogram(\n",
    "            prod_noisy_voice, dim_square_spec, n_fft, hop_length_fft)\n",
    "\n",
    "    # Save to disk for Training / QC\n",
    "    np.save(path_save_time_serie + 'voice_timeserie', prod_voice)\n",
    "    np.save(path_save_time_serie + 'noise_timeserie', prod_noise)\n",
    "    np.save(path_save_time_serie + 'noisy_voice_timeserie', prod_noisy_voice)\n",
    "\n",
    "\n",
    "    np.save(path_save_spectrogram + 'voice_amp_db', m_amp_db_voice)\n",
    "    np.save(path_save_spectrogram + 'noise_amp_db', m_amp_db_noise)\n",
    "    np.save(path_save_spectrogram + 'noisy_voice_amp_db', m_amp_db_noisy_voice)\n",
    "\n",
    "    np.save(path_save_spectrogram + 'voice_pha_db', m_pha_voice)\n",
    "    np.save(path_save_spectrogram + 'noise_pha_db', m_pha_noise)\n",
    "    np.save(path_save_spectrogram + 'noisy_voice_pha_db', m_pha_noisy_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load params\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# mode = config['MODE']['mode'].split(',')[0]\n",
    "\n",
    "#folder containing noises and clean voices\n",
    "noise_dir = config['RAW_DATA']['noise_dir'].split(',')[0]\n",
    "voice_dir = config['RAW_DATA']['voice_dir'].split(',')[0]\n",
    "\n",
    "#path to save time series, sounds and spectrograms\n",
    "path_save_time_serie = config['DATA']['path_save_time_serie'].split(',')[0]\n",
    "path_save_sound = config['DATA']['path_save_sound'].split(',')[0]\n",
    "path_save_spectrogram = config['DATA']['path_save_spectrogram'].split(',')[0]\n",
    "\n",
    "# Sample rate to read audio\n",
    "sample_rate = int(config['PREPROCESS']['sample_rate'].split(',')[0])\n",
    "# Minimum duration of audio files to consider\n",
    "min_duration = float(config['PREPROCESS']['min_duration'].split(',')[0])\n",
    "#Frame length for training data\n",
    "frame_length = int(config['PREPROCESS']['frame_length'].split(',')[0])\n",
    "# hop length for clean voice files\n",
    "hop_length_frame = int(config['PREPROCESS']['hop_length_frame'].split(',')[0])\n",
    "# hop length for noise files\n",
    "hop_length_frame_noise = int(config['PREPROCESS']['hop_length_frame_noise'].split(',')[0])\n",
    "# How much frame to create for training\n",
    "nb_samples = int(config['PARAMETER']['nb_samples'].split(',')[0])\n",
    "#nb of points for fft(for spectrogram computation)\n",
    "n_fft = int(config['PREPROCESS']['n_fft'].split(',')[0])\n",
    "#hop length for fft\n",
    "hop_length_fft = int(config['PREPROCESS']['hop_length_fft'].split(',')[0])\n",
    "\n",
    "create_data(noise_dir, voice_dir, path_save_time_serie, path_save_sound, path_save_spectrogram, sample_rate,\n",
    "min_duration, frame_length, hop_length_frame, hop_length_frame_noise, nb_samples, n_fft, hop_length_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
